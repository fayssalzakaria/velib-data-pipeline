#  V√©lib' Data Pipeline with Apache Airflow, Railway & AWS S3

Ce projet d√©ploie un pipeline de donn√©es complet autour du service V√©lib‚Äô M√©tropole √† Paris. Il permet de collecter, transformer, stocker et analyser les donn√©es de disponibilit√© des v√©los via un DAG Apache Airflow. L‚Äôinfrastructure est h√©berg√©e sur [Railway](https://railway.app) : **√† la fois le scheduler Airflow et la base de donn√©es PostgreSQL**. Les fichiers sont archiv√©s sur AWS S3.

---

##  Objectifs du projet

-  **Collecte automatique** des donn√©es V√©lib‚Äô en temps r√©el via l‚ÄôAPI opendata.paris.fr
-  **Transformation & nettoyage** des donn√©es JSON en format tabulaire (Pandas DataFrame)
-  **Insertion dans une base PostgreSQL Railway**
-  **Sauvegarde locale & envoi vers AWS S3** sous forme de fichiers CSV
-  **G√©n√©ration automatique de rapports PDF** (graphiques & stats) √©galement envoy√©s sur S3
-  **Orchestration compl√®te et planification horaire via Apache Airflow**
-  **Export horaire vers S3 pour usage personnel ou int√©gration avec Power BI**

---

## üéØ Fonctionnement

Chaque heure :
1. Les donn√©es sont extraites depuis l‚ÄôAPI V√©lib‚Äô.
2. Elles sont nettoy√©es et enrichies via `Pandas`.
3. Elles sont ins√©r√©es dans une base PostgreSQL d√©ploy√©e sur Railway.
4. Elles sont export√©es au format `.csv` (sauvegarde locale + upload vers AWS S3).
5. Un rapport PDF est g√©n√©r√© avec des graphiques synth√©tiques et aussi envoy√© sur S3.

üóÇÔ∏è **Le fichier CSV courant peut √™tre utilis√© dans Power BI**, et  
üìÑ **le rapport PDF est t√©l√©chargeable √† des fins de suivi ou de reporting personnel.**

---

## ‚öôÔ∏è Technologies utilis√©es

- **Apache Airflow** (Dockeris√©, d√©ploy√© sur Railway)
- **Python 3.9+**
- **Railway** (d√©ploiement du serveur Airflow **et** de la base PostgreSQL)
- **AWS S3** (stockage de fichiers)
- **Pandas / Matplotlib**
- **SQLAlchemy**
- **Requests** (API REST V√©lib‚Äô)

---

## üìÇ Structure du projet

velib-data-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ airflow/
‚îÇ ‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ velib_dag.py # DAG principal Airflow
‚îÇ ‚îî‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ fetch.py # Requ√™te API V√©lib‚Äô
‚îÇ ‚îú‚îÄ‚îÄ transform.py # Nettoyage & enrichissement
‚îÇ ‚îú‚îÄ‚îÄ insert.py # Insertion SQL (Railway PostgreSQL)
‚îÇ ‚îú‚îÄ‚îÄ save.py # Sauvegarde CSV + S3
‚îÇ ‚îî‚îÄ‚îÄ generate_report.py # Rapport PDF + Upload S3
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile # Environnement Airflow
‚îú‚îÄ‚îÄ entrypoint.sh # Lancement Webserver + Scheduler
‚îú‚îÄ‚îÄ requirements.txt # D√©pendances Python
‚îî‚îÄ‚îÄ .env / Railway Variables # Cl√©s AWS, URL DB, bucket S3...
## Rapport pdf
Le rapport contient :

Top 10 stations avec le plus de v√©los

Top 10 stations vides

R√©partition des √©tats des stations

Plus grandes stations par capacit√©

##  API de t√©l√©chargement ‚Äì FastAPI

Une API FastAPI l√©g√®re est int√©gr√©e au projet pour permettre le **t√©l√©chargement √† distance** des fichiers g√©n√©r√©s (rapport PDF et dernier CSV), directement depuis AWS S3.

Cette API est expos√©e sur Railway (port 8081) en parall√®le du serveur Airflow (port 8080).

### üîó Endpoints disponibles

| Endpoint | Description |
|----------|-------------|
| `/download/report` | üìÑ T√©l√©charge le dernier rapport PDF (`report.pdf`) |
| `/download/csv`    | üìÅ T√©l√©charge le dernier fichier CSV (`velib_...csv`) |

> Exemple :  
> `https://<ton-projet>.railway.app:8081/download/report`  
> `https://<ton-projet>.railway.app:8081/download/csv`

---

###  Utilisations typiques

-  **Analyste ou d√©cideur** : T√©l√©charger et visualiser le rapport PDF synth√©tique (graphiques).
-  **Utilisateur Power BI / Excel** : R√©cup√©rer le dernier CSV pour cr√©er des tableaux de bord interactifs.

---

### ‚öô Stack technique de l‚ÄôAPI

- **FastAPI** : framework l√©ger pour cr√©er des endpoints REST
- **Uvicorn** : serveur ASGI rapide
- **Boto3** : SDK AWS pour r√©cup√©rer les fichiers S3
- Ex√©cut√©e en parall√®le d'Airflow depuis `entrypoint.sh`

---
