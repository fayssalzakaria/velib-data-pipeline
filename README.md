#  VÃ©lib' Data Pipeline with Apache Airflow, Railway & AWS S3

Ce projet dÃ©ploie un pipeline de donnÃ©es complet autour du service VÃ©libâ€™ MÃ©tropole Ã  Paris. Il permet de collecter, transformer, stocker et analyser les donnÃ©es de disponibilitÃ© des vÃ©los via un DAG Apache Airflow. Lâ€™infrastructure est hÃ©bergÃ©e sur [Railway](https://railway.app) : **Ã  la fois le scheduler Airflow et la base de donnÃ©es PostgreSQL**. Les fichiers sont archivÃ©s sur AWS S3.

---

##  Objectifs du projet

-  **Collecte automatique** des donnÃ©es VÃ©libâ€™ en temps rÃ©el via lâ€™API opendata.paris.fr
-  **Transformation & nettoyage** des donnÃ©es JSON en format tabulaire (Pandas DataFrame)
-  **Insertion dans une base PostgreSQL Railway**
-  **Sauvegarde locale & envoi vers AWS S3** sous forme de fichiers CSV
-  **GÃ©nÃ©ration automatique de rapports PDF** (graphiques & stats) Ã©galement envoyÃ©s sur S3
-  **Orchestration complÃ¨te et planification horaire via Apache Airflow**
-  **Export horaire vers S3 pour usage personnel ou intÃ©gration avec Power BI**

---

## ğŸ¯ Fonctionnement

Chaque heure :
1. Les donnÃ©es sont extraites depuis lâ€™API VÃ©libâ€™.
2. Elles sont nettoyÃ©es et enrichies via `Pandas`.
3. Elles sont insÃ©rÃ©es dans une base PostgreSQL dÃ©ployÃ©e sur Railway.
4. Elles sont exportÃ©es au format `.csv` (sauvegarde locale + upload vers AWS S3).
5. Un rapport PDF est gÃ©nÃ©rÃ© avec des graphiques synthÃ©tiques et aussi envoyÃ© sur S3.

ğŸ—‚ï¸ **Le fichier CSV courant peut Ãªtre utilisÃ© dans Power BI**, et  
ğŸ“„ **le rapport PDF est tÃ©lÃ©chargeable Ã  des fins de suivi ou de reporting personnel.**

---

## âš™ï¸ Technologies utilisÃ©es

- **Apache Airflow** (DockerisÃ©, dÃ©ployÃ© sur Railway)
- **Python 3.9+**
- **Railway** (dÃ©ploiement du serveur Airflow **et** de la base PostgreSQL)
- **AWS S3** (stockage de fichiers)
- **Pandas / Matplotlib**
- **SQLAlchemy**
- **Requests** (API REST VÃ©libâ€™)

---
```
## ğŸ“‚ Structure du projet

velib-data-pipeline/
â”‚
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â””â”€â”€ velib_dag.py # DAG principal Airflow
â”‚ â””â”€â”€ scripts/
â”‚ â”œâ”€â”€ fetch.py # RequÃªte API VÃ©libâ€™
â”‚ â”œâ”€â”€ transform.py # Nettoyage & enrichissement
â”‚ â”œâ”€â”€ insert.py # Insertion SQL (Railway PostgreSQL)
â”‚ â”œâ”€â”€ save.py # Sauvegarde CSV + S3
â”‚ â””â”€â”€ generate_report.py # Rapport PDF + Upload S3
â”‚
â”œâ”€â”€ Dockerfile # Environnement Airflow
â”œâ”€â”€ entrypoint.sh # Lancement Webserver + Scheduler
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â””â”€â”€ .env / Railway Variables # ClÃ©s AWS, URL DB, bucket S3...
```
## Rapport pdf
Le rapport contient :

Top 10 stations avec le plus de vÃ©los

Top 10 stations vides

RÃ©partition des Ã©tats des stations

Plus grandes stations par capacitÃ©

##  API de tÃ©lÃ©chargement â€“ FastAPI

Une API FastAPI lÃ©gÃ¨re est intÃ©grÃ©e au projet pour permettre le **tÃ©lÃ©chargement Ã  distance** des fichiers gÃ©nÃ©rÃ©s (rapport PDF et dernier CSV), directement depuis AWS S3.

Cette API est exposÃ©e sur Railway (port 8081) en parallÃ¨le du serveur Airflow (port 8080).

### ğŸ”— Endpoints disponibles

| Endpoint | Description |
|----------|-------------|
| `/download/report` | ğŸ“„ TÃ©lÃ©charge le dernier rapport PDF (`report.pdf`) |
| `/download/csv`    | ğŸ“ TÃ©lÃ©charge le dernier fichier CSV (`velib_...csv`) |

lien de base (
pour acceder a airflow)
pour acceder a airflow)

Lien de base (pour accÃ©der Ã  Airflow) :https://velib-data-pipeline-production.up.railway.app/

---

###  Utilisations typiques

-  **Analyste ou dÃ©cideur** : TÃ©lÃ©charger et visualiser le rapport PDF synthÃ©tique (graphiques).
-  **Utilisateur Power BI / Excel** : RÃ©cupÃ©rer le dernier CSV pour crÃ©er des tableaux de bord interactifs.

---

### âš™ Stack technique de lâ€™API

- **FastAPI** : framework lÃ©ger pour crÃ©er des endpoints REST
- **Uvicorn** : serveur ASGI rapide
- **Boto3** : SDK AWS pour rÃ©cupÃ©rer les fichiers S3
- ExÃ©cutÃ©e en parallÃ¨le d'Airflow depuis `entrypoint.sh`

---
